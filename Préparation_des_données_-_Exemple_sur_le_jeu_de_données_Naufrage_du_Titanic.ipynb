{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystalloide/Big_Data/blob/master/Pr%C3%A9paration_des_donn%C3%A9es_-_Exemple_sur_le_jeu_de_donn%C3%A9es_Naufrage_du_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade kagglehub"
      ],
      "metadata": {
        "id": "ExFT8AtGYGLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# IMPORTANT : CERTAINES SOURCES DE DONNÉES KAGGLE SONT PRIVÉES\n",
        "# EXÉCUTEZ CETTE CELLULE POUR IMPORTER VOS SOURCES DE DONNÉES KAGGLE.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "6UkNvlzy8muH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Si besoin de copier un fichier disponible dans Google drive :\n",
        "# file_id = '13Tcjs7ut-cBOEK46rMQ7OTANuk9kOmsz'\n",
        "#\n",
        "# fn = 'Fichier_exemple.txt'\n",
        "#\n",
        "#download_link = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "#\n",
        "# !wget \"{download_link}\" -O \"{fn}\""
      ],
      "metadata": {
        "id": "G-5DY4L3TObJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# IMPORTANT : EXÉCUTEZ CETTE CELLULE POUR IMPORTER VOS SOURCES DE DONNÉES KAGGLE,\n",
        "# PUIS, N'HÉSITEZ PAS À SUPPRIMER CETTE CELLULE.\n",
        "# REMARQUE : CET ENVIRONNEMENT PORTABLE DIFFÈRE DE L'ENVIRONNEMENT PYTHON DE KAGGLE.\n",
        "# IL PEUT DONC MANQUER DES BIBLIOTHÈQUES UTILISÉES PAR VOTRE PORTABLE.\n",
        "\n",
        "titanic_path = kagglehub.competition_download('titanic')\n",
        "\n",
        "print('Data source import complete.')\n",
        "\n",
        "!ls\n",
        "!pwd\n",
        "!rm gender_submission.csv\n",
        "!rm test.csv\n",
        "!rm train.csv\n",
        "!unzip titanic.zip\n",
        "\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "fzH-yyjN8muI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "_uuid": "fa1c06c3245237b07d584ac9984675953f90bcc2",
        "id": "fhurNBsc8muI"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tutoriel général de préparation des données**\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "4bbfe635e70581311314c3d6111742a953d20e3d",
        "id": "mZOayC6m8muJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Bienvenue dans ce tutoriel de préparation de données.\n",
        "\n",
        "### Ce notebook est destiné à montrer les étapes de préparation d'un jeu de données\n",
        "### avant de le transmettre à un algorithme de machine learning.\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "ab319b6d81ba9248843b1ad2758d3878a384c466",
        "id": "-TAyCIyJ8muJ"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://2s7gjr373w3x22jf92z99mgm5w-wpengine.netdna-ssl.com/wp-content/uploads/2016/07/shutterstock_data_prep_-faithie.jpg)"
      ]
    },
    {
      "metadata": {
        "_uuid": "b578e8fc813355bbcf0e887c0120c4ddb5b14ab6",
        "id": "AYWWwBrb8muJ"
      },
      "cell_type": "markdown",
      "source": [
        "### Voici quelques ressources supplémentaires que vous pouvez consulter pour approfondir la compréhension des différentes techniques que nous allons voir dans ce cahier :"
      ]
    },
    {
      "metadata": {
        "_uuid": "50283e1cb80921d96364b582dafad1723512d221",
        "id": "B0fQB43m8muK"
      },
      "cell_type": "markdown",
      "source": [
        "[*Gérer les valeurs manquantes*](https://towardsdatascience.com/tag/handling-missing-values/)\n",
        "\n",
        "[*Ingénierie des fonctionnalités*](https://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/)\n",
        "\n",
        "[*Pourquoi l'encodage à chaud en apprentissage automatique ?*](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)\n",
        "\n",
        "[*Piège à variables fictives*](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
        "\n",
        "[*Encodage à chaud*](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)\n",
        "\n",
        "[*Mise à l'échelle et Normalisation*](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e)"
      ]
    },
    {
      "metadata": {
        "_uuid": "685dee8f16e05ef7eb8b90078aba46e802ecd61a",
        "id": "9av9L91-8muK"
      },
      "cell_type": "markdown",
      "source": [
        "## **Table des matières**"
      ]
    },
    {
      "metadata": {
        "_uuid": "386676783fb199ab10ceac466ed8ffd4aa206b86",
        "id": "4D2WZSz08muK"
      },
      "cell_type": "markdown",
      "source": [
        "[**1. Traitement des valeurs manquantes et des valeurs aberrantes**](#1)\n",
        "\n",
        "[**2. Ingénierie des caractéristiques**](#2)\n",
        "\n",
        "[**3. Gestion des fonctionnalités catégorielles**](#3)\n",
        "\n",
        "[**4. Mise à l'échelle des caractéristiques**](#4)"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ZXIfpn4r8muK"
      },
      "cell_type": "code",
      "source": [
        "!pip install chart-studio\n",
        "!pip install numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import missingno as mn\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import iplot, init_notebook_mode\n",
        "import cufflinks as cf\n",
        "cf.go_offline(connected=True)\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def draw_missing_data_table(df):\n",
        "    total = df.isnull().sum().sort_values(ascending=False)\n",
        "    percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
        "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "    return missing_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "FrD_aPy98muL"
      },
      "cell_type": "code",
      "source": [
        "# Path of datasets\n",
        "titanic_df = pd.read_csv('train.csv')\n",
        "titanic_df.head()\n",
        "# display(titanic_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ddd3eba2b4f6366ab0d98f469a15cc0450a85941",
        "id": "EDK0oT2c8muL"
      },
      "cell_type": "markdown",
      "source": [
        "## **1. Traitement des valeurs manquantes et des valeurs aberrantes** <a id=\"1\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "a831e5f105f5ac9cf9cab593833b0602991cbe5c",
        "id": "yKd5w2698muL"
      },
      "cell_type": "markdown",
      "source": [
        "#### Le 1er problème rencontré lors de la préparation des données pour leur transmission à un algorithme d'apprentissage automatique est celui des données manquantes.\n",
        "#### En effet, les jeux de données massifs et/ou ceux issus de données réelles, présentent des valeurs manquantes.\n",
        "#### Par exemple, notre jeu de données titanesque présente des valeurs manquantes :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8253704df6dc5b0f0d74e35b661b8ec428bd8195",
        "id": "XQsYBDEG8muL"
      },
      "cell_type": "code",
      "source": [
        "missing_values = titanic_df\n",
        "sns.heatmap(missing_values.isnull(), cbar=False)\n",
        "# Option 1 :\n",
        "plt.show()\n",
        "# Option 2 :\n",
        "mn.matrix(missing_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5392a9719179a729cf1ef15b50c59c3a438fb1b8",
        "id": "6LJoGCUV8muL"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Si une caractéristique (= une colonne du jeu de données) a des valeurs manquantes, il y a un choix à faire :\n",
        "\n",
        "### - S'il y a trop de données manquantes (> 60 %), il faudra alors peut-être supprimer la colonne :\n",
        "\n",
        "### titanic_df.drop('Cabin', axis=1, inplace=True)\n",
        "\n",
        "### - S'il y a peu de données manquantes (1 à 2 %), on peut envisager de supprimer ces lignes contenant NAN :\n",
        "\n",
        "### titanic_df['Age'].dropna(inplace=True)\n"
      ]
    },
    {
      "metadata": {
        "_uuid": "5392a9719179a729cf1ef15b50c59c3a438fb1b8",
        "id": "_-OWrfxpenyb"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### - En général, on ne souhaite pas perdre de données :\n",
        "\n",
        "### Pour un petit nombre de données manquantes, une meilleure solution  consiste donc à étudier chaque observation au cas par cas\n",
        "### et à remplacer les valeurs manquantes en examinant d'autres caractéristiques de cette observation,\n",
        "### puis en essayant de trouver une tendance entre elles afin de déterminer la valeur manquante.\n",
        "\n",
        "### Une 1ère solution consiste à remplacer les valeurs manquantes par la moyenne ou la médiane de la colonne.\n",
        "### On privilégie la médiane pour des colonnes contenant des valeurs aberrantes susceptibles de fausser la moyenne.\n",
        "\n",
        "#### titanic_df['Age'].fillna(titanic_df['Age'].mean(), 1, inplace=True)\n",
        "#### titanic_df['Age'].fillna(titanic_df['Age'].median(), 1, inplace=True)\n",
        "\n",
        "### La stratégie de remplissage des valeurs manquantes dépend fortement du jeu de données et de votre imagination !\n",
        "### Il faut se demander pourquoi ces données sont manquantes et comment les remplacer intelligemment !\n",
        "### N'oubliez pas d'essayer différentes méthodes de remplacement et de mesurer leur impact sur les performances du modèle.\n",
        "\n",
        "### Examinons maintenant notre jeu de données Titanic :"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(titanic_df.columns)"
      ],
      "metadata": {
        "id": "dMPFZiP5s-uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_missing_data_table(titanic_df[['Cabin', 'Age', 'Embarked']])"
      ],
      "metadata": {
        "id": "RSR2J90ea3xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c8da6fc848902000a7b356dfa59f11b5d0b988fa",
        "id": "1AafYY5B8muL"
      },
      "cell_type": "markdown",
      "source": [
        "#### Comme on le voit, il ne manque que deux valeurs pour la colonne « Embarked ». Essayons donc de les remplacer.\n",
        "\n",
        "#### Voici la répartition des valeurs de la colonne « Embarked » selon le tarif et le sexe, ainsi que les deux observations pour lesquelles la valeur « Embarked » est manquante.\n",
        "\n",
        "#### Analysons ces deux observations et choisissons la valeur « Embarked» la plus adaptée en fonction de leur tarif et de leur sexe :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e5d71f475f8236bd0df71852f6a52e4889026562",
        "id": "5R2ETm5_8muL"
      },
      "cell_type": "code",
      "source": [
        "# Agrégation des données pour obtenir la moyenne et l'erreur standard (SEM) de Fare selon \"Embarked\" et \"Sex\"\n",
        "group_stats = titanic_df.groupby(['Embarked','Sex']).agg(mean_fare=('Fare', 'mean'), std_fare=('Fare', 'std'), count=('Fare', 'count')).reset_index()\n",
        "group_stats['sem'] = group_stats['std_fare'] / np.sqrt(group_stats['count'])\n",
        "\n",
        "# Création d'une palette inspirée du colormap nipy_spectral pour deux\n",
        "# catégories\n",
        "colors = [mcolors.to_hex(cm.nipy_spectral(0.2)),\n",
        "          mcolors.to_hex(cm.nipy_spectral(0.8))]\n",
        "\n",
        "# Création du graphique en barres groupées avec barres d'erreur\n",
        "fig = px.bar(group_stats,\n",
        "             x=\"Embarked\",\n",
        "             y=\"mean_fare\",\n",
        "             color=\"Sex\",\n",
        "             barmode='group',\n",
        "             error_y='sem',\n",
        "             color_discrete_sequence=colors,\n",
        "             title=\"Tarif (Fare) en fonction du port d'embarquement et du sexe\",\n",
        "             labels={\"mean_fare\": \"Fare\", \"Embarked\": \"Port d'embarquement\", \"Sex\": \"Sexe\"})\n",
        "\n",
        "# Ajustement de la taille de la figure (pour correspondre à figsize=(20, 8))\n",
        "new_var = fig.update_layout(width=200, height=80)\n",
        "new_var\n",
        "\n",
        "# fig.show()\n",
        "\n",
        "# figure, axes = plt.subplots(1,1,figsize=(20, 8))\n",
        "# plot = sns.catplot(x=\"Embarked\", y=\"Fare\", hue=\"Sex\", data=titanic_df, palette=('nipy_spectral'), kind=\"bar\", ax=axes)\n",
        "# plt.close(plot.fig)\n",
        "# plt.show()\n",
        "\n",
        "display(titanic_df[titanic_df['Embarked'].isnull()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "96d8fa62c76b2e756e501444c99552dd4aa98829",
        "id": "jC_LLgOe8muM"
      },
      "cell_type": "markdown",
      "source": [
        "### Les deux passagères sont des femmes qui ont payé 80 dollars pour leur billet. De plus, elles ont le même billet et la même cabine ; elles ont donc probablement dû embarquer au même endroit ! D'après la distribution ci-dessus, la valeur d'embarquement la plus probable pour elles est Cherbourg (C). Remplaçons ces valeurs manquantes :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "160380a05b7fe957b109da0290ee446ff933c85b",
        "id": "E9FXyEzg8muM"
      },
      "cell_type": "code",
      "source": [
        "titanic_df['Embarked'].fillna('C', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pour l'âge, nous avons 177 valeurs manquantes  ! => C'est beaucoup trop pour les examiner au cas par cas."
      ],
      "metadata": {
        "id": "TYPUXuy2aqM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(int(titanic_df['Age'].isnull().sum()))"
      ],
      "metadata": {
        "id": "XRGH4FB1Z0oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(titanic_df[titanic_df['Age'].isnull()])"
      ],
      "metadata": {
        "id": "uwiveRJwZrMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1680eb602baf52fec30bc425f0fca7d6a92e214d",
        "id": "hzSK8HKo8muM"
      },
      "cell_type": "markdown",
      "source": [
        "#### Nous allons remplacer les valeurs manquantes par la valeur médiane, même s'il existe peut-être une meilleure solution prenant en compte d'autres colonnes.\n",
        "\n",
        "#### Si vous trouvez une solution pour remplacer les valeurs d'âge manquantes qui améliore considérablement la précision de votre modèle, n'hésitez pas à la proposer !"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3713234249422bee05b53f333ab127f551ca7934",
        "id": "Ofh27naw8muM"
      },
      "cell_type": "code",
      "source": [
        "titanic_df['Age'].fillna(titanic_df['Age'].median(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b9a4bcc1d712e8a283f201afa5ffd777e311452a",
        "id": "5mbIc2jq8muM"
      },
      "cell_type": "markdown",
      "source": [
        "#### Enfin, la colonne « Cabin » (cabine) permet de trouver le pont où se trouve la cabine du passager :\n",
        "#### => nous la conserverons donc.\n",
        "\n",
        "#### Remplaçons les valeurs manquantes par « U », c'est-à-dire 'Unkown':"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "892039639905363f4e5e26736e83bfe2cb2671e7",
        "id": "hpdNJiYP8muM"
      },
      "cell_type": "code",
      "source": [
        "titanic_df['Cabin'].fillna('U', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "658a2ae96bf806569521ea616ec3cba49a452cb3",
        "id": "XUap7DBM8muM"
      },
      "cell_type": "code",
      "source": [
        "draw_missing_data_table(titanic_df[['Cabin', 'Age', 'Embarked']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fcdf726a3377e5f093b178fcae07651662eb3e0e",
        "id": "uFRKyI0F8muM"
      },
      "cell_type": "markdown",
      "source": [
        "## **2. Ingénierie des caractéristiques** <a id=\"2\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "94def9bb6e7d8e66e0c47ded26ef10243883072c",
        "id": "UqLRgcVX8muM"
      },
      "cell_type": "markdown",
      "source": [
        "### L'ingénierie des caractéristiques est l'art de créer de nouvelles caractéristiques à partir de caractéristiques existantes ou de connaissances sur les données.\n",
        "\n",
        "#### Par exemple, une simple recherche sur Internet permet de savoir que la première lettre de la colonne « cabine » correspond au pont du bateau où se trouve la cabine.\n",
        "#### Ainsi, nous pouvons créer une entité « Pont » à partir de la caractéristiques « cabine ».\n",
        "\n",
        "#### Nous pouvons également créer une colonne « Title » correspondant au titre de chaque passager.\n",
        "\n",
        "#### La création de caractéristiques est la seule limite !\n",
        "\n",
        "#### Mais l'objectif n'est pas de créer des caractéristiques simplement pour créer des caractéristiques, mais d'améliorer la précision du modèle !\n",
        "\n",
        "#### Voici quelques exemples de création de caractéristiques pour le jeu de données Titanic :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8daa8401d9316696a5bdecad95807c5e593649ec",
        "id": "t62lsXM68muM"
      },
      "cell_type": "code",
      "source": [
        "# Deck column from letter contained in cabin\n",
        "titanic_df['Deck'] = titanic_df['Cabin'].str[:1]\n",
        "titanic_df['Deck'] = titanic_df['Cabin'].map({cabin: p for p, cabin in enumerate(set(cab for cab in titanic_df['Cabin']))})\n",
        "\n",
        "# Title column from title contained in name\n",
        "titanic_df['Title'] = pd.Series((name.split('.')[0].split(',')[1].strip() for name in titanic_df['Name']), index=titanic_df.index)\n",
        "titanic_df['Title'] = titanic_df['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "titanic_df['Title'] = titanic_df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
        "titanic_df['Title'] = titanic_df['Title'].replace('Mme', 'Mrs')\n",
        "\n",
        "# Famillysize columns obtained by adding number of sibling and parch\n",
        "titanic_df['FamillySize'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
        "titanic_df['FamillySize'][titanic_df['FamillySize'].between(1, 5, inclusive='neither')] = 2\n",
        "titanic_df['FamillySize'][titanic_df['FamillySize']>5] = 3\n",
        "titanic_df['FamillySize'] = titanic_df['FamillySize'].map({1: 'Alone', 2: 'Medium', 3: 'Large'})\n",
        "\n",
        "# IsAlone and IsChild column, quite explicit\n",
        "titanic_df['IsAlone'] = np.where(titanic_df['FamillySize']!=1, 0, 1)\n",
        "titanic_df['IsChild'] = titanic_df['Age'] < 18\n",
        "titanic_df['IsChild'] = titanic_df['IsChild'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d118e47ade8afeba0d947d24ac45eca4d1277338",
        "id": "21V0nF5f8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Une fois que nous avons terminé de créer nos nouvelles fonctionnalités, nous pouvons supprimer toutes les colonnes restantes qui seront inutiles et afficher les premières lignes de notre dataset :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f55056111610891accfda70fcc8fee07a84eefb",
        "id": "E76qypbY8muN"
      },
      "cell_type": "code",
      "source": [
        "titanic_df = titanic_df.drop(['Name', 'Ticket', 'PassengerId', 'Cabin'], axis=1)\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c6a2b251a8ae431def02d1c23ff6c0aa2792c370",
        "id": "Q_ybhk-08muN"
      },
      "cell_type": "markdown",
      "source": [
        "## **3. Gestion des fonctionnalités catégorielles** <a id=\"3\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "c153f7f9e43c2b84925f110ca597a59d92a47f42",
        "id": "7U_aaIMq8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Comme vous pouvez le constater en examinant l'ensemble de données ci-dessus, nos données contiennent des caractéristiques catégorielles.\n",
        "### Ces caractéristiques sont des caractéristiques dont les valeurs ne sont pas numériques.\n",
        "### Nous avons quatre colonnes de type catégorie :\n",
        "  - Sex\n",
        "  - Embarked\n",
        "  - Title\n",
        "  - FamilySize\n",
        "\n",
        "### Nous devons les transformer en caractéristiques numériques avant de pouvoir les transmettre à un algorithme de machine learning.\n",
        "\n",
        "### Une solution consiste à transformer ces caractéristiques en caractéristiques numériques en mappant les valeurs de chaîne avec des valeurs numériques. Cette solution est appelée \"label encoding\" (codage d'étiquettes).\n",
        "### Elle est facile à réaliser en Python à l'aide de la classe LabelEncoder de Scikit Learn ou de la méthode map d'un dataframe Pandas.\n",
        "### Par exemple, pour encoder par étiquette la colonne \"Embarked\" du jeu de données Titanic, nous allons créer de nouvelles colonnes à partir de \"embarked\" en y ajoutant la lettre de la ville d'embarquement  : la valeur \"string\" de la ville sera remplacé par une valeur de type \"number\" distincte dans les 3 colonnes crées correspondant au lieu d'embarquement :\n",
        "\n",
        "- Embarqué à Cherbourg (\"Embarked_C\") correspond à 1\n",
        "- Embarqué à Southampton (\"Embarked_S\") correspond à 2\n",
        "- Embarqué à Queenstown (\"Embarked_Q\") correspond à 3\n",
        "\n",
        "### Le problème est que l'algorithme peut interpréter cela comme un classement entre les trois valeurs.\n",
        "\n",
        "\n",
        "### Alternative conseillée :\n",
        "\n",
        "### Une meilleure solution consiste à utiliser l'encodage « hot-one ».\n",
        "\n",
        "### Ce codage consiste à créer une colonne par valeur de la colonne source (appelée variable muette), qui prend uniquement des valeurs binaires. Par exemple, la colonne « embarked » « dummy encoded » donne trois colonnes : Embarked_C, Embarked_S et Embarked_Q. Par exemple, la colonne « Embarked_S » d'un passager ayant embarqué à Southampton sera définie à 1, tandis que les deux autres colonnes « embarked » seront définies à 0.\n",
        "\n",
        "### Cependant, cette méthode crée une colonne redondante : avec deux des trois colonnes « Embarked », on peut facilement deviner la valeur de la troisième colonne.\n",
        "### Par exemple, un passager dont les colonnes Embarked_C et Embarked_S sont définies à 0 aura nécessairement sa colonne Embarked_Q définie à 1.\n",
        "### Afin d'éviter cette redondance, appelée piège de la variable factice, nous devons supprimer l'une des colonnes créées lors de la création d'une variable factice.\n",
        "\n",
        "*Remarque : L'encodage one-hot est généralement efficace, mais cela peut varier au cas par cas. N'hésitez pas à tester l'effet de l'encodage one-hot sur votre modèle pour voir si vous en avez besoin.*\n",
        "\n",
        "### Il existe une méthode très simple pour effectuer un encodage one-hot en Python : la fonction pandas get_dummies crée un encodage one-hot pour toutes les caractéristiques catégorielles d'un jeu de données.\n",
        "### En ajoutant l'argument drop_first=True, nous supprimons une colonne pour chaque variable factice à encoder."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2cd8757a652f90674dfb6972f99c3b55a225a397",
        "id": "R_YuVC-X8muN"
      },
      "cell_type": "code",
      "source": [
        "titanic_df = pd.get_dummies(data=titanic_df, drop_first=True)\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ea021e657727b1e65c9cada661ed5ae492c62202",
        "id": "MJuUm4Jq8muN"
      },
      "cell_type": "markdown",
      "source": [
        "## **4. Mise à l'échelle des caractéristiques** <a id=\"4\"></a>"
      ]
    },
    {
      "metadata": {
        "_uuid": "ba96a06d76b3a858459486ceb0af2340a7799074",
        "id": "4b9sAO8M8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Enfin, nous devons normaliser les données.\n",
        "\n",
        "#### Cette normalisation est nécessaire,\n",
        "#### car alimenter un modèle de machine learning avec des valeurs nombreuses ou hétérogènes\n",
        "#### peut déclencher d'importantes mises à jour de gradient,\n",
        "#### empêchant ainsi la convergence de l'algorithme de descente de gradient.\n",
        "\n",
        "_\n",
        "\n",
        "#### Examinons les plages de valeurs de notre dataframe :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hw5lbp0a8muN"
      },
      "cell_type": "code",
      "source": [
        "# Calcul des valeurs maximales des colonnes sélectionnées\n",
        "ranges = titanic_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Deck', 'IsChild']].max().to_frame().T\n",
        "\n",
        "# Affichage du graphique\n",
        "# ranges.iplot(kind='bar', xTitle='Features', yTitle='Range', title='Plage de fonctionnalités avant mise à l échelle',\n",
        "#             colors=['rgba(255, 153, 51, 1.0)'])  # Correction du format de couleur\n",
        "\n",
        "# Création du graphique à partir des valeurs maximales calculées\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Bar(\n",
        "            x=ranges.columns,\n",
        "            y=ranges.iloc[0],\n",
        "            marker=dict(\n",
        "                color='#FF9933',         # Couleur de remplissage\n",
        "                line=dict(\n",
        "                    color='#FF9933',     # Couleur de la bordure\n",
        "                    width=1\n",
        "                )\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Plage de fonctionnalités avant mise à l échelle',\n",
        "    xaxis_title='Features',\n",
        "    yaxis_title='Range'\n",
        ")\n",
        "fig.show()\n",
        "\n",
        "# ranges = titanic_df[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Deck', 'IsChild']].max().to_frame().T\n",
        "# ranges.iplot(kind='bar', xTitle='Features', yTitle='Range', title='Range of feature before scaling')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pxWDqCRA8muN"
      },
      "cell_type": "markdown",
      "source": [
        "### Les plages sont très hétérogènes.\n",
        "\n",
        "### Une façon de remédier à cela est d'utiliser la mise à l'échelle des caractéristiques ('features scaling').\n",
        "\n",
        "### Cette mise à l'échelle définit la moyenne de chaque colonne à 0 et la variance de chaque colonne à 1.\n",
        "\n",
        "### En Python, la classe StandarScaler du module scikit-learn permet de le faire très facilement :"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "46fdee99c06403f18ef1201671c3c8903193e8c4",
        "id": "6VPiiOOq8muN"
      },
      "cell_type": "code",
      "source": [
        "X = titanic_df.drop(['Survived'], axis=1)\n",
        "y = titanic_df['Survived']\n",
        "\n",
        "# Feature scaling of our data\n",
        "sc = StandardScaler()\n",
        "X = pd.DataFrame(sc.fit_transform(X.values), index=X.index, columns=X.columns)\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "926c3da68404487f08462c699bb4725d819578b9",
        "id": "BSFFFNZO8muO"
      },
      "cell_type": "markdown",
      "source": [
        "### Et voilà ! Notre jeu de données est enfin prêt à intégrer un algorithme d'apprentissage automatique !\n",
        "\n",
        "#### N'oubliez pas de consulter les 2 autres notebooks pour ce jeu de données :\n",
        "\n",
        "- [**Complete Titanic tutorial with ML, NN & Ensembling**](https://www.kaggle.com/nhlr21/complete-titanic-tutorial-with-ml-nn-ensembling)\n",
        "- [**Titanic colorful EDA**](https://www.kaggle.com/nhlr21/titanic-colorful-eda)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}